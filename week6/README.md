# Assignment 5

## FOUNDATION EXERCISES
[Previous coursework from MSSE 642](https://github.com/b-a-merritt/msse642/blob/main/assignment5/Assignment5CollaborationFile.md)

Place for __Sree G.__ to contribute: (can write something here and make a PR)

## ADVANCED EXERCISES

### Film to watch: [Deep Fakes](https://moondisaster.org/)

## Who is responsible when the output is deceptive? Explore the idea of accountability in generative systems. If a deepfake spreads misinformation, who is to blame â€” the model, the developer, or the user? In SE, who is responsible for bugs that escape testing?

The criteron of whether a technology is culpable--and thereby its creators--rests on two things:

1) What is was created for, and
2) It's capacity for good

The inventor of dynamite, Alfred Bernhard Nobel, was so grieved by the use of his invention that he initiated the Nobel Prize as recompense. However, it was clearly not created as a weapon of war, nor is its uses limited to destruction. It can clear debris to save trapped miners, for example. It is much safer than it's predecessor, gunpowder, and can greatly aid the construction of bridges, tunnels, and other civil projects. It's capacity for good outweights the bad.

Nuclear weapons, however, were neither created with good ends nor do they have the capability for good. They were intended for destruction and can do nothing more. While they may be redeemed by the fact that having them deters others from using them, everyone can agree that it would be better if no one had them. Their capacity for good is outweighed by their evil. By our criteria, nuclear weapons are bad.

AI was not created for bad and it has many good applications. It has made great strides in solving the proteign folding problem, for example, something that, if solved, could help various medical ailments. By our definition, it doesn't seem bad.

But there is nuance. While Adobe photoshop is likely not a bad thing, I could use it to do bad things, like making slanderous photos of individuals. Worse, I could make a tool in photoshop that makes generating slanderous photos even easier. That tool is not the same thing as photoshop itself. Just because photoshop is not a bad thing does not mean it blanket makes anything that uses it not bad as well. An AI tool that makes deepfake slanderous content is intrinsically evil. 

To answer the question, is the developer of the AI model responsible? No. They did not create the deepfake tool. Is the developer of the deepfake tool culpable? Yes. 
